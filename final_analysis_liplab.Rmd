---
title: "MAPS"
author: "Ian Hussey"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# To do

- delete "style and reporting requirements notes" and "old code to be adapted" below before submission
- HOW THE FUCK DO I GET A SINGLE OR OUT OF A MODEL, AS THE SUBMISSION REQUIRES? ordinal models provide it in different units (which? sth about the latent scale units), gaussian models in the manifest variable scale, and multinominal logistic models provide multiple odds ratios relative to the reference category.

# Style and reporting requirements

- new variable names must be prepended with "n_"
- new parameters named IN_SHOUTING_SNAKE_CASE and at the start of functions with comment explaning them, including a min and max value.

```{r include=FALSE}

# formatting options

# set default chunk options
knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE, 
                      echo = TRUE)

# disable scientific notation
options(scipen = 999) 

# knitr output for html
options(knitr.table.format = "html")

```

# Version info

```{r}

TEAM_NAME <- "liplab"

VERSION <- version$version.string

# # Save session info on development machine (only). Commented out as it shouldn't be run in the centralized analyses, only on the local development machine.
# writeLines(capture.output(sessionInfo()), "session_info_liplab.txt")

```
# Workflow

## Dependencies

NB these should be loaded in each function according to the style guide, therefore this chunk should eventually be removed.

```{r}

# dependencies
library(tidyverse)
library(brms)
library(brmstools)
library(sjPlot)
library(sjstats)
library(parallel)
library(knitr)
library(kableExtra)
library(timesavers)
library(patchwork)

```

## Load data

```{r}

load_data <- function(path){
  
  # imports 
  library(tidyverse)
  
  data <- read.csv(path) %>%
    dplyr::select(comp_week,
                  comp_wend,
                  dep_band_15,
                  dep_score,
                  dep_thoughts,
                  has_dep_diag)
  
  return(data)
}

data <- load_data(path = "maps-synthetic-data.csv")

```


### dev chunk

```{r}

data %>%
  mutate_all(.funs = is.na) %>%
  summarize_all(.funs = mean)

data %>%
  count(comp_week) %>%
  arrange(desc(n))

data %>%
  count(comp_wend) %>%
  arrange(desc(n))

data %>%
  count(dep_band_15) %>%
  arrange(desc(n))

data %>%
  count(dep_score) %>%
  arrange(desc(n))

data %>%
  count(dep_thoughts) %>%
  arrange(desc(n))

data %>%
  count(has_dep_diag) %>%
  arrange(desc(n))

```

## Outliers

```{r}

outliers_001 <- function(data){
  
  # # imports 
  # library(tidyverse)
  # 
  # data <- read.csv(path) %>%
  #   dplyr::select(comp_week,
  #                 comp_wend,
  #                 dep_band_15,
  #                 dep_score,
  #                 dep_thoughts,
  #                 has_dep_diag)
  
  return(data)
}

data <- outliers_001(data)

```

## Missing

see https://cran.r-project.org/web/packages/brms/vignettes/brms_missings.html

```{r}

missing_001 <- function(data){
  
  # # imports 
  # library(tidyverse)
  # 
  # data <- read.csv(path) %>%
  #   dplyr::select(comp_week,
  #                 comp_wend,
  #                 dep_band_15,
  #                 dep_score,
  #                 dep_thoughts,
  #                 has_dep_diag)
  
  return(data)
}

data <- missing_001(data)

```

## Define depression

```{r}

depression_001 <- function(data){
  
  # imports
  library(tidyverse)
  
  data <- data %>%
    dplyr::mutate(depression = as.ordered(dep_score))
  
  return(data)
}

data <- depression_001(data)

#levels(data$depression)

```

## Define computer use

```{r}

computer_use_001 <- function(data){
  
  # imports
  library(tidyverse)
  library(forcats)
  
  data <- data %>%
    # dplyr::mutate(comp_use_1 = forcats::fct_relevel(comp_week,
    #                                                 "Not at all",
    #                                                 "Less than 1 hour",
    #                                                 "1-2 hours", 
    #                                                 "3 or more hours"),
    #               comp_use_2 = forcats::fct_relevel(comp_wend,
    #                                                 "Not at all",
    #                                                 "Less than 1 hour",
    #                                                 "1-2 hours", 
    #                                                 "3 or more hours"))
    dplyr::mutate(comp_use_1 = dplyr::recode(comp_week,
                                             "Not at all" = 0,
                                             "Less than 1 hour" = 1,
                                             "1-2 hours" = 2,
                                             "3 or more hours" = 3),
                  comp_use_2 = dplyr::recode(comp_wend,
                                             "Not at all" = 0,
                                             "Less than 1 hour" = 1,
                                             "1-2 hours" = 2,
                                             "3 or more hours" = 3))
  
  return(data)
}

data <- computer_use_001(data)

```

## Additional

```{r}

additional_001 <- function(data){
  
  # # imports 
  # library(tidyverse)
  # 
  
  return(data)
}

data <- additional_001(data)

```

## Specify model

results: a named list containing the following:
● “mod” = model object
● “or_1” = your first odds ratio
● “p_1” = the p-value corresponding to “or_1”
● “ci_1”= the 95% confidence interval corresponding to “or_1”)
● “or_2” = your second odds ratio
● “p_2” = the p-value corresponding to “or_2”
● “ci_2”= the 95% confidence interval corresponding to “or_2”
● “AIC” = the AIC value
● “DIC” = the DIC value

```{r}

specify_model <- function(data){
  
  # # imports 
  # library(tidyverse)
  
  return(results)
}

results <- specify_model(data)

```


# Old code to be adapted

## Fit model

Should it be one model or two, for the two different computer variables? Given that they're correlated (are they?) why partial them out from one another?

```{r}

cor.test(data$comp_use_1, data$comp_use_2, use = "pairwise.complete.obs")

cor.test(data$comp_use_1, as.numeric(data$depression), use = "pairwise.complete.obs")
cor.test(data$comp_use_2, as.numeric(data$depression), use = "pairwise.complete.obs")

```

### Multinominal

#### d ~ comp_use_1 + comp_use_2

```{r}

mod_multinominal <- brm(formula = depression ~ comp_use_1 + comp_use_2,
                        data = data, 
                        family = cumulative("logit"),
                        #prior = c(set_prior("normal(0, 1)", class = "b")),
                        iter = 2000,
                        chains = 4,
                        control = list(adapt_delta = 0.95),
                        cores = detectCores(),
                        file = "mod_multinominal")

summary(mod_multinominal)

hypothesis(mod_multinominal, "comp_use_1 > 0", alpha = .05)
hypothesis(mod_multinominal, "comp_use_1 < 0", alpha = .05)

hypothesis(mod_multinominal, "comp_use_2 > 0", alpha = .05)
hypothesis(mod_multinominal, "comp_use_2 < 0", alpha = .05)
posterior_interval(mod_multinominal)

plot_model(mod_multinominal,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot_model(mod_multinominal,
           type = "pred",
           terms = c("comp_use_1"))

plot_model(mod_multinominal,
           type = "pred",
           terms = c("comp_use_2"))

```

#### d ~ comp_use_1 

##### ordinal logit

```{r}

mod1_multinominal <- brm(formula = depression ~ comp_use_1,
                         data = data, 
                         family = cumulative("logit"),
                         #prior = c(set_prior("normal(0, 1)", class = "b")),
                         iter = 2000,
                         chains = 4,
                         control = list(adapt_delta = 0.95),
                         cores = detectCores(),
                         file = "mod1_multinominal")

summary(mod1_multinominal)

hypothesis(mod1_multinominal, "comp_use_1 > 0", alpha = .05)
hypothesis(mod1_multinominal, "comp_use_1 < 0", alpha = .05)
posterior_interval(mod1_multinominal)

plot_model(mod1_multinominal,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot_model(mod1_multinominal,
           type = "pred",
           terms = c("comp_use_1"))

```

##### ordinal probit

```{r}

mod1_multinominal_probit <- brm(formula = depression ~ comp_use_1,
                                data = data, 
                                family = cumulative("probit"),
                                iter = 2000,
                                chains = 4,
                                control = list(adapt_delta = 0.95),
                                cores = detectCores(),
                                file = "mod1_multinominal_probit")

summary(mod1_multinominal_probit)

hypothesis(mod1_multinominal_probit, "comp_use_1 > 0", alpha = .05)
hypothesis(mod1_multinominal_probit, "comp_use_1 < 0", alpha = .05)
posterior_interval(mod1_multinominal_probit)

plot_model(mod1_multinominal_probit,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot_model(mod1_multinominal_probit,
           type = "pred",
           terms = c("comp_use_1"))

```

##### multinominal

```{r}

# https://thinkinator.com/2016/01/12/r-users-will-now-inevitably-become-bayesians/

mod1_multinominal_categorical <- brm(formula = depression ~ comp_use_1,
                                data = data, 
                                family = categorical(),
                                prior = c(set_prior ("normal (0, 8)")),
                                iter = 2000,
                                chains = 4,
                                control = list(adapt_delta = 0.95),
                                cores = detectCores(),
                                file = "mod1_multinominal_categorical")

summary(mod1_multinominal_categorical)

marginal_effects(mod1_multinominal_categorical, categorical = TRUE)

# hypothesis(mod1_multinominal_categorical, "comp_use_1 > 0", alpha = .05)
# hypothesis(mod1_multinominal_categorical, "comp_use_1 < 0", alpha = .05)
# posterior_interval(mod1_multinominal_categorical)

exp(posterior_interval(mod1_multinominal_categorical))

plot_model(mod1_multinominal_categorical,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot_model(mod1_multinominal_categorical,
           type = "pred",
           terms = c("comp_use_1"))

```

#### d ~ comp_use_2

```{r}

mod2_multinominal <- brm(formula = depression ~ comp_use_2,
                         data = data, 
                         family = cumulative("logit"),
                         #prior = c(set_prior("normal(0, 1)", class = "b")),
                         iter = 2000,
                         chains = 4,
                         control = list(adapt_delta = 0.95),
                         cores = detectCores(),
                         file = "mod2_multinominal")

summary(mod2_multinominal)

hypothesis(mod2_multinominal, "comp_use_2 > 0", alpha = .05)
hypothesis(mod2_multinominal, "comp_use_2 < 0", alpha = .05)
posterior_interval(mod2_multinominal)

plot_model(mod2_multinominal,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot_model(mod2_multinominal,
           type = "pred",
           terms = c("comp_use_2"))

```

### Gaussian

```{r}

mod_gaussian <- brm(formula = as.integer(depression) ~ comp_use_1 + comp_use_2,
                    data = data, 
                    family = gaussian(link = "identity"),
                    #prior = c(set_prior("normal(0, 1)", class = "b")),
                    iter = 2000,
                    chains = 4,
                    control = list(adapt_delta = 0.95),
                    cores = detectCores(),
                    file = "mod_gaussian")

summary(mod_gaussian)

hypothesis(mod_gaussian, "comp_use_1 > 0", alpha = .05)
hypothesis(mod_gaussian, "comp_use_1 < 0", alpha = .05)

hypothesis(mod_gaussian, "comp_use_2 > 0", alpha = .05)
hypothesis(mod_gaussian, "comp_use_2 < 0", alpha = .05)
posterior_interval(mod_gaussian)

plot_model(mod_gaussian,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot_model(mod_gaussian,
           type = "pred",
           terms = c("comp_use_1"))

plot_model(mod_gaussian,
           type = "pred",
           terms = c("comp_use_2"))

```


```{r}

mod1_gaussian <- brm(formula = as.integer(depression) ~ comp_use_1,
                     data = data, 
                     family = gaussian(link = "identity"),
                     #prior = c(set_prior("normal(0, 1)", class = "b")),
                     iter = 2000,
                     chains = 4,
                     control = list(adapt_delta = 0.95),
                     cores = detectCores(),
                     file = "mod1_gaussian")

summary(mod1_gaussian)

hypothesis(mod1_gaussian, "comp_use_1 > 0", alpha = .05)
hypothesis(mod1_gaussian, "comp_use_1 < 0", alpha = .05)
posterior_interval(mod1_gaussian)

plot_model(mod1_gaussian,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot_model(mod1_gaussian,
           type = "pred",
           terms = c("comp_use_1"))

```


```{r}

mod2_gaussian <- brm(formula = as.integer(depression) ~ comp_use_2,
                     data = data, 
                     family = gaussian(link = "identity"),
                     #prior = c(set_prior("normal(0, 1)", class = "b")),
                     iter = 2000,
                     chains = 4,
                     control = list(adapt_delta = 0.95),
                     cores = detectCores(),
                     file = "mod2_gaussian")

summary(mod2_gaussian)

hypothesis(mod2_gaussian, "comp_use_2 > 0", alpha = .05)
hypothesis(mod2_gaussian, "comp_use_2 < 0", alpha = .05)
posterior_interval(mod2_gaussian)

plot_model(mod2_gaussian,
           prob.inner = 0.5, 
           prob.outer = 0.95)

plot_model(mod2_gaussian,
           type = "pred",
           terms = c("comp_use_2"))

```

- why do hypothesis() and posterior_interval produce different intervals??

```{r}

summary(mod2)$fixed %>%
  as.data.frame()



hypothesis(mod, "comp_use_1 > 0", alpha = .05)
hypothesis(mod, "comp_use_2 > 0", alpha = .05)

hypothesis(mod, "comp_use_1 < 0", alpha = .05)
hypothesis(mod, "comp_use_2 < 0", alpha = .05)

posterior_samples(mod) %>%
  select(b_comp_use_1) %>%
  mutate(b_comp_use_1_greater_than_zero = ifelse(b_comp_use_1 > 0, TRUE, FALSE)) %>%
  summarize(pp = mean(b_comp_use_1_greater_than_zero))

posterior_samples(mod) %>%
  select(b_comp_use_2) %>%
  mutate(b_comp_use_2_greater_than_zero = ifelse(b_comp_use_2 > 0, TRUE, FALSE)) %>%
  summarize(pp = mean(b_comp_use_2_greater_than_zero))

posterior_interval(mod)

```

## Posterior checks

```{r}

#pp_check(fit_bayes_ar, nsamples = 10) 

plot(fit_bayes_ar, ask = FALSE)

```

## Results 

```{r}

# fixed effects
ROPE_data <- rope(fit_bayes_ar, rope = c(-0.5, 0.5)) %>%    # NEEDS MUCH THOUGHT
  dplyr::rename(Parameter = term,
                `% inside ROPE` = rope) %>%
  filter(grepl("b_", Parameter) & !grepl("prior", Parameter)) %>% 
  mutate(Parameter = str_replace_all(Parameter, "b_", ""),
         Parameter = str_replace_all(Parameter, "[.]", ":"))

results_data <- summary(fit_bayes_ar)$fixed %>%
  as.data.frame() %>%
  rownames_to_column(var = "Parameter") %>%
  dplyr::rename(SE = Est.Error,
                Lower = `l-95% CI`,
                Upper = `u-95% CI`) %>%
  full_join(ROPE_data, by = "Parameter") %>%
  round_df(2)

results_data %>%
  dplyr::select(Parameter, Estimate, SE, Lower, Upper, 
                `% inside ROPE`, Eff.Sample, Rhat) %>%
  mutate(Estimate = round(Estimate, 2),
         SE = round(SE, 2),
         Lower = round(Lower, 2),
         Upper = round(Upper, 2)) %>%
  kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)


# correlation between residuals
summary(fit_bayes_ar)$rescor_pars %>%
  as.data.frame() %>%
  rownames_to_column(var = "parameter") %>%
  round_df(2) %>%
  kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

# autoregressive effects
summary(fit_bayes_ar)$cor_pars %>%
  as.data.frame() %>%
  rownames_to_column(var = "parameter") %>%
  round_df(2) %>%
  kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

# bayes factors
## Savage-Dickey Bayes Factor (BF10)
BF_shame_sav_dic <- fit_bayes_ar %>% 
  hypothesis(hypothesis = "ScoreShame_ConditionB = 0", alpha = .05)  

BF_act_sav_dic <- fit_bayes_ar %>% 
  hypothesis(hypothesis = "ScoreACT_ConditionB = 0", alpha = .05)  

## Posterior evidence ratio (Bayesian p value)
BF_shame_post_evid_ratio <- fit_bayes_ar %>% 
  hypothesis(hypothesis = "ScoreShame_ConditionB < 0", alpha = .05)  

BF_act_post_evid_ratio <- fit_bayes_ar %>% 
  hypothesis(hypothesis = "ScoreACT_ConditionB < 0", alpha = .05)  

```

Bayes Factors:

Shame:

- Savage-Dickey Bayes Factor (BF10) = `r round(1/BF_shame_sav_dic$hypothesis$Evid.Ratio, 3)`.
- 1-Posterior evidence ratio (Bayesian *p* value) = `r round(1/BF_shame_post_evid_ratio$hypothesis$Evid.Ratio, 5)`.

ACT:

- Savage-Dickey Bayes Factor (BF10) = `r round(1/BF_act_sav_dic$hypothesis$Evid.Ratio, 3)`.
- 1-Posterior evidence ratio (Bayesian *p* value) = `r round(1/BF_act_post_evid_ratio$hypothesis$Evid.Ratio, 5)`.

### Plot prior vs posterior

```{r}

plot(BF_shame_sav_dic)

plot(BF_act_sav_dic)

```

### Association between change on the two DVs

```{r fig.height=3, fig.width=9}

posterior <- fit_bayes_ar %>%
  tidycoef() %>%
  round_df(2)

posterior_dv_betas <- posterior %>%
  filter(Parameter %in% c("ScoreShame_ConditionB", "ScoreACT_ConditionB") &
           !is.na(Participant)) %>%
  spread(Parameter, value) %>%
  rename(Shame = ScoreShame_ConditionB,
         ACT = ScoreACT_ConditionB)

# collated
p1 <- 
  ggplot(posterior_dv_betas, aes(Shame, ACT)) +
  geom_hex(bins = 40) + 
  geom_vline(aes(xintercept = median(Shame)), 
             linetype = "dashed") +
  geom_hline(aes(yintercept = median(ACT)), 
             linetype = "dashed") +
  geom_smooth(method = "lm", color = "orange") +
  geom_abline(slope = 1, intercept = 0) +
  xlim(-2.2, 0.2) +
  ylim(-2.2, 0.2) +
  xlab("Posterior distribution \nstandardized beta for Shame") +
  ylab("Posterior distribution \nstandardized beta for ACT") +
  theme_classic() +
  scale_fill_viridis_c() + 
  theme(legend.position = "none")

# by participant
posterior_summaries <- posterior_dv_betas %>%
  group_by(Participant) %>%
  summarize(median_Shame = median(Shame),
            median_ACT   = median(ACT))

p2 <- 
  ggplot(posterior_dv_betas, aes(Shame, ACT)) +
  facet_wrap(~Participant) +
  geom_hex(bins = 40) + 
  geom_vline(data = posterior_summaries, 
             aes(xintercept = median_Shame), 
             linetype = "dashed",
             color = 1) +
  geom_hline(data = posterior_summaries, 
             aes(yintercept = median_ACT), 
             linetype = "dashed",
             color = 1) +
  geom_smooth(method = "lm", color = "orange") +
  geom_abline(slope = 1, intercept = 0) +
  xlim(-2.2, 0.2) +
  ylim(-2.2, 0.2) +
  xlab("Posterior distribution \nstandardized beta for Shame") +
  ylab("Posterior distribution \nstandardized beta for ACT") +
  theme_classic() +
  scale_fill_viridis_c() + 
  theme(legend.position = "none")

p3 <- 
  ggplot(posterior_summaries, aes(median_Shame, median_ACT)) +
  geom_point() +
  geom_smooth(method = "lm", color = "orange") +
  geom_abline(slope = 1, intercept = 0) +
  xlim(-1.5, -0.5) +
  ylim(-1.5, -0.5) +
  xlab("Posterior distribution \nstandardized beta for Shame") +
  ylab("Posterior distribution \nstandardized beta for ACT") +
  theme_classic() +
  scale_fill_viridis_c() + 
  theme(legend.position = "none")

p1 + p2 + p3

cor.test(posterior_dv_betas$ACT, posterior_dv_betas$Shame)

#summary(brm(ACT ~ Shame, data = posterior_dv_betas))

```

