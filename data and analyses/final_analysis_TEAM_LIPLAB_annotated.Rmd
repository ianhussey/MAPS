---
title: "MAPS"
author: "Ian Hussey"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

The MAPS team provided strict guidelines on how code should be formatted. My final submission is therefore a separate .R file that includes only the necessary functions from the below code. This file serves to provide additional details to explicate my workflow and thinking, as well as illustrating the results in tables and plots.

# Justification of analytic strategy

Our straegy was to attempt to answer the research question that was posed and not other questions. I think that there is a distinction between flexibility in the analytic approach used to answer a given question and flexibility in the (re)interpretation of what the question is (or worse, “really” is or should be). 

The research question was defined by the MAPS team as "Is computer use during weekdays and weekends at 16 years old associated with depression at 18 years old?".

I interpreted each element of this research question as follows:

1. "computer use during weekdays and weekends" was interpreted as "(computer use during weekdays) and (computer use during weekends)". There is much scope for alternative interpretations, such as by pooling the two variables, or pooling them and weighting them to attempt to quantify the total hours per week, etc. However, given that the response format was ordinal (ie max was "3+ hours"), the latter would introduce great uncertainty. As such, I work with the native data format. This meant answering the two questions (depression ~ computer use weekdays and depression ~ computer use weekends) separately. I should note that, as far as I understand, Khouja et al. (2019) reduced this to three categories by merging the none and less than one hour categories. However, the article was not explicit about this as far as I can see.
  - This straggy therefore diverges from our understanding of what Khouja et al. (2019) did, who seem to have recoded the four ordinal levels to three (i.e. they merged the zero and the less than 1 hour options. 
  - Equally, I was careful not to over interpret the question as asking about the relative prediction of these two types of computer usage: I computed two separate models (depression ~ computer use weekdays and depression ~ computer use weekends) rather than a single model containing both computer usage variables (e.g., depression ~ computer use weekdays + computer use weekends), as the latter would instead ask whether the unique contribution of one type of computer usage predicted depression after controlling for the other type. I note that this was the strategy employed by Khouja et al. (2019). 
2. "16 years old" was interpreted as "the nearest timepoint to 16 years old", which was 15.5. 
3. "associated with" was interpreted as meaning an association, not necessarially a causation. That is, I did not over interpret the research question to examine whether computer use caused depression (e.g., by predicting change in depression between the two timepoints due to computer use at the first timepoint). I think this point is particularly important to acknowledge. Given the prospective design, I think it is likely the reader may misinterpret any such association as implying causality, even if implicitly. Of course, finding any association could equally be explained by depression levels being relatively static between the two timepoints and a) depression causing computer usage, or b) a third variable causing both. Given that this topic is likely to be read (and potentially misinterpreted) by many concerned parents, this possibility must be highlighted, in our opinion. Indeed, the more meaningful question might well be whether there is likely to be a causal link between computer usage and symptoms of psychopathology, however, it is not the question asked by the MAPS team. As I noted above, in addition to flexibility in the analytic approach used to answer a given question, flexibility in the (re)interpretation of what the question is (or worse, “really” is or should be), likely represent an even greater number of experimenter degrees of freedom. As such, I attempt to answer the question as literally as possible.
4. "depression" was interpreted as depressive symptoms. Multiple depression related variables were present in the data. I elect to employ dep_score on the basis that it is defined as symptoms of depression rather than merely depressive thoughts. In addition, the depressive thoughts variable was conditionally branched from depression symptoms - it was not delivered if a depression symptoms response of 0 was provided. Although depressive thoughts could notionally be expected to have better lowerbound sensitivity than overt symptoms, this use of conditional branching made symptoms more appropriate in my opinion. A diagnosis of depression variable (has_dep_diag) was also present in the data. However, this score represents a compound scoring of symptoms and thoughts. As such, the more granular symptoms variable was considered most suitable for analysis. The DAWBA depression bands were also considered as a potential DV. However, given a) the very poor correlations between depressive symptoms and the algorithmic diagnosis of depression provided by the DAWBA bands, b) the historic reliance on self reports of depressive symptoms rather than algorithmic integration of responses by the individual as well as their caregivers, and c) my lack of exertise with such algorithmic probabilty bands and their acceptiability within the depression literature, I elected to rely solely on the depressive symtoms variable as my outcome measure (e.g., rather than other or multiple variables in a multivariate model). 
   
5. "at 18 years old" was interpreted as "the nearest timepoint to 18 years old", which was 17.5. 

On the basis of our above interpretations of the question, I therefore elected to analyze the data using (Bayesian) Ordinal Regression models, on the basis that both depression and computer use were ordinal. This was done using the brms package (see Burkner & Vuorre, 2018, Ordinal Regression Models in Psychology: A Tutorial, doi: 10.1177/2515245918823199). 

```{r include=FALSE}

# set default chunk options
knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE, 
                      echo = TRUE)

# disable scientific notation
options(scipen = 999) 

# knitr output for html
options(knitr.table.format = "html")

```

# Version info

```{r}

TEAM_NAME <- "LIPLAB"

VERSION <- version$version.string

```

# Workflow

## Dependencies

```{r}

# dependencies
library(tidyverse)
library(brms)
library(parallel)
library(brmstools)
library(sjPlot)
library(knitr)
library(kableExtra)
#library(devtools); install_github("ianhussey/timesavers")
library(timesavers) 

# Save session info 
writeLines(capture.output(sessionInfo()), "session_info_TEAM_LIPLAB.txt")

```

## Load data

```{r}

load_data <- function(path){
  
  # IMPORTS 
  library(tidyverse)
  
  # SELECT DATA
  data <- read.csv(path) %>%
    dplyr::select(comp_week,
                  comp_wend,
                  dep_score,
                  dep_thoughts,
                  has_dep_diag,
                  dep_band_15)
  
  return(data)
}

data <- load_data(path = "maps-synthetic-data-v1.1.csv")

```

### Distributions

Assess data missingness betwee depression variables

```{r}

data %>%
  mutate_all(.funs = is.na) %>%
  summarize_all(.funs = mean) %>%
  timesavers::round_df(2) %>%
  gather(variable, percent_missing) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data %>%
  count(comp_week) %>%
  arrange(desc(n)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data %>%
  count(comp_wend) %>%
  arrange(desc(n)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data %>%
  count(dep_band_15) %>%
  arrange(desc(n)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data %>%
  count(dep_score) %>%
  arrange(desc(n)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data %>%
  count(dep_thoughts) %>%
  arrange(desc(n)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data %>%
  count(has_dep_diag) %>%
  arrange(desc(n)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Bivariate associations between two depression variables

```{r}

# exploration of correlation between two different metrics of depression

# reshape data
temp <- data %>%
  mutate(dep_band_15_new = recode(dep_band_15,
                                  "<0.1%"	= 1,
                                  "~0.5%" = 2,
                                  "~15%" = 3,
                                  "~50%" = 4,
                                  ">70%" = 5)) 

# ordinal correlation between dep_score and dep_band_15
correlation <- cor(as.numeric(temp$dep_score), 
    as.numeric(temp$dep_band_15_new), 
    use = "pairwise.complete.obs", 
    method = "spearman")

# jittered scatter plot
ggplot(temp, aes(dep_score, dep_band_15_new)) +
  geom_jitter() +
  geom_smooth(method = "lm")

```

Spearman correlation between the ordinal categories of dep_score and dep_band_15 was r = `r round(correlation, 3)`.

## Define computer use

```{r}

computer_use_001 <- function(data){
  
  # IMPORTS
  library(tidyverse)
  library(forcats)
  
  # SET ORDERED LEVELS
  # comp_use_1 and comp_use_2 are both defined using their original four oridinal levels of these variables found in the dataset. 
  # code below simply ensures that the data type is set to ordinal (ie an ordered factor) and the levels are correctly ordered 
  data <- data %>%
    dplyr::mutate(comp_use_1 = forcats::fct_relevel(comp_week,  # set ordering among levels
                                                    "Not at all",
                                                    "Less than 1 hour",
                                                    "1-2 hours",
                                                    "3 or more hours"),
                  comp_use_1 = as.ordered(comp_use_1),  # change data type to ordered factor
                  comp_use_2 = forcats::fct_relevel(comp_wend,  # set ordering among levels
                                                    "Not at all",
                                                    "Less than 1 hour",
                                                    "1-2 hours",
                                                    "3 or more hours"),
                  comp_use_2 = as.ordered(comp_use_2))  # change data type to ordered factor
  
  return(data)
}

data <- computer_use_001(data)

```

## Define depression

```{r}

depression_001 <- function(data){
  
  # IMPORTS
  library(tidyverse)
  
  # SET ORDERED LEVELS
  # depression is defined as the dep_score variable, using the oridinal levels of this variable found in the dataset. 
  # code below simply ensures that the data type is set to ordinal (ie an ordered factor)
  data <- data %>%
    dplyr::mutate(depression = as.ordered(dep_score))  # change data type to ordered factor
  
  return(data)
}

data <- depression_001(data)

```

### Check levels

Ensure the ordinal categories are ordered correctly.

```{r}

levels(data$depression)
levels(data$comp_use_1)
levels(data$comp_use_2)

```

## Outliers

No assessment of multivariate outliers was done. Given ordinal scales, inspection of the distributions suggested there were no univariate outliers, therefore no data points were exluded as outliers.   

## Missing

Data missingness is high. Indeed, it is so high that multiple imputation is not reccomended in my opinion.

## Weightings

I considered adding weightings for sex in order to increase the representativeness of the results. However, inspection of the data demonstrated that the sample was 52% female/48% male, which is sufficiently close to the population distribution that I thought it wasn't worth the additional complexity. 

## Specify model

## Get prior

I employ the default brms prior (t distribution on all parameters with M = 0 and df = 3), which in this case is quite weak and non-informative. Results using the synthetic dataset suggest that data easily overwhelm the prior.

```{r}

get_prior(formula = as.ordered(depression) ~ as.ordered(comp_use_1),
          data = data,
          family = cumulative("logit"))

```

### Fit model
               
```{r}

specify_model <- function(data, N_ITERATIONS, N_CHAINS, CONTROL_LIST){
  
  # IMPORTS
  library(tidyverse)
  library(brms)  # nb requires brms 2.8+
  library(parallel)
  
  # MODEL 1: depression ~ comp_use_1
  mod_1 <- brms::brm(formula      = depression ~ comp_use_1,
                     data         = data,
                     family       = cumulative("logit"),
                     sample_prior = TRUE,
                     iter         = N_ITERATIONS,
                     chains       = N_CHAINS,
                     control      = CONTROL_LIST,
                     cores        = detectCores(),
                     file         = "TEAM_LIPLAB_mod_1")
  
  # ADD WAIC TO MODEL
  mod_1 <- add_criterion(mod_1, "waic")
  
  # EXTRACT WAIC VALUE
  n_waic_1 <- mod_1$waic$estimates %>%
    as.data.frame() %>%
    rownames_to_column(var = "coefficient") %>%
    filter(coefficient == "waic") %>%
    pull(Estimate) %>%
    as.numeric()
  
  # CONVERT LOG ODDS TO ODDS RATIOS 
  n_odds_ratios_1 <- posterior_summary(mod_1) %>%
    exp() %>%  
    as.data.frame() %>%
    rownames_to_column(var = "effect") %>%
    filter(effect == "b_comp_use_1.L")  # extract effect for linear trend
  
  or_1 <- n_odds_ratios_1 %>%
    pull(Estimate) %>%
    as.numeric()
  
  n_ci_1_lower <- n_odds_ratios_1 %>%
    pull(Q2.5) %>%
    as.numeric()
  
  n_ci_1_upper <- n_odds_ratios_1 %>%
    pull(Q97.5) %>%
    as.numeric()
  
  ci_1 <- c(n_ci_1_lower, n_ci_1_upper)
  
  
  # MODEL 2: depression ~ comp_use_2
  mod_2 <- brms::brm(formula      = depression ~ comp_use_2,
                     data         = data,
                     family       = cumulative("logit"),
                     sample_prior = TRUE,
                     iter         = N_ITERATIONS,
                     chains       = N_CHAINS,
                     control      = CONTROL_LIST,
                     cores        = detectCores(),
                     file         = "TEAM_LIPLAB_mod_2")
  
  # ADD WAIC TO MODEL
  mod_2 <- add_criterion(mod_2, "waic")
  
  # EXTRACT WAIC VALUE
  n_waic_2 <- mod_2$waic$estimates %>%
    as.data.frame() %>%
    rownames_to_column(var = "coefficient") %>%
    filter(coefficient == "waic") %>%
    pull(Estimate) %>%
    as.numeric()
  
  # CONVERT LOG ODDS TO ODDS RATIOS 
  n_odds_ratios_2 <- posterior_summary(mod_2) %>%
    exp() %>%  # convert log odds to odds ratios
    as.data.frame() %>%
    rownames_to_column(var = "effect") %>%
    filter(effect == "b_comp_use_2.L")  # extract effect for linear trend
  
  or_2 <- n_odds_ratios_2 %>%
    pull(Estimate) %>%
    as.numeric()
  
  n_ci_2_lower <- n_odds_ratios_2 %>%
    pull(Q2.5) %>%
    as.numeric()
  
  n_ci_2_upper <- n_odds_ratios_2 %>%
    pull(Q97.5) %>%
    as.numeric()
  
  ci_2 <- c(n_ci_2_lower, n_ci_2_upper)
  
  # RETURN RESULTS LIST
  return(list(data = data, 
              mod   = list(mod_1 = mod_1, 
                           mod_2 = mod_2), 
              or_1  = or_1,
              ci_1  = ci_1,
              p_1   = NA,
              or_2  = or_2,
              ci_2  = ci_2,
              p_2   = NA,
              AIC   = NA,
              WAIC  = list(WAIC_1 = n_waic_1,
                           WAIC_2 = n_waic_2))) 
  
}

# APPLY FUNCTION TO DATA
results <- specify_model(data, 
                         CONTROL_LIST = list(adapt_delta = 0.95),
                         N_ITERATIONS = 2000,
                         N_CHAINS = 4)

```

# Inspect model convergence

## Model 1

```{r fig.height=7, fig.width=5}

plot(results$mod$mod_1, ask = FALSE)

```

```{r}

pp_check(results$mod$mod_1, nsamples = 100)

```

```{r}

summary(results$mod$mod_1)$fixed %>%
  as.data.frame() %>%
  round_df(2) %>%
  select(Eff.Sample, Rhat) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

## Model 2

```{r fig.height=7, fig.width=5}

plot(results$mod$mod_2, ask = FALSE)

```

```{r}

pp_check(results$mod$mod_2, nsamples = 100)

```

```{r}

summary(results$mod$mod_2)$fixed %>%
  as.data.frame() %>%
  round_df(2) %>%
  select(Eff.Sample, Rhat) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# View results

```{r}

# table
data.frame(iv = c("computer weekdays", "computer weekends"),
           OR = c(results$or_1, results$or_2),
           CI_lower = c(results$ci_1[1], results$ci_2[1]),
           CI_upper = c(results$ci_1[2], results$ci_2[2]),
           bayesian_p = c(results$p_1, results$p_2)) %>%
  timesavers::round_df(2) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)
  
```

## Computer use weekdays

```{r}

plot_model(results$mod$mod_1,
           prob.inner = 0.5,
           prob.outer = 0.95)

marginal_effects(results$mod$mod_1,
                 "comp_use_1",
                 categorical = TRUE)

```

## Computer use weekends

```{r}

plot_model(results$mod$mod_2,
           prob.inner = 0.5,
           prob.outer = 0.95)

marginal_effects(results$mod$mod_2,
                 "comp_use_2",
                 categorical = TRUE)

```


